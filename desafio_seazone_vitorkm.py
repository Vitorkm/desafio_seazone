# -*- coding: utf-8 -*-
"""Desafio_Seazone_VitorKM.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/155-mrLTSxQYOF6aFyC9RR6A94WVitruH
"""

import pandas as pd
import numpy as np
import requests
from bs4 import BeautifulSoup
import json

listaJson = []


def aquisicaodeDadosOLX(pages):
    for x in range(0, pages):
        url = "https://sc.olx.com.br/florianopolis-e-regiao/imoveis/terrenos?o=" + str(
            x
        )

        parametros = {
            "authority": "pr.olx.com.br",
            "method": "GET",
            "path": "/florianopolis-e-regiao/imoveis/terrenos",
            "scheme": "https",
            "referrer": "https://sc.olx.com.br/florianopolis-e-regiao/imoveis/terrenos",
            "sec-fetch-mode": "navigate",
            "sec-fetch-site": "same-origin",
            "sec-fetch-user": "?1",
            "upgrade-insecure-requests": "1",
            "user-agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/79.0.3945.130 Safari/537.36",
        }

        page = requests.get(url=url, headers=parametros)
        soup = BeautifulSoup(page.content, "lxml")
        anuncios = soup.find_all("li", {"class": "sc-1fcmfeb-2 fvbmlV"})

        for a in anuncios:
            try:

                paginaAnuncio = a.find("a")["href"]

                tamanhoAnuncio = a.find_all(
                    "span", class_="sc-1j5op1p-0 lnqdIU sc-ifAKCX eLPYJb"
                )[0].contents[0]
                tamanhoAnuncio = tamanhoAnuncio.split("|")[0]
                localAnuncio = a.find_all(
                    "span", class_="sc-7l84qu-1 ciykCV sc-ifAKCX dpURtf"
                )[0].contents[0]
                horarioAnuncio = a.find_all(
                    "p", class_="sc-1iuc9a2-3 kcOvhi sc-ifAKCX fWUyFm"
                )[0].contents[0]
                horarioAnuncio = horarioAnuncio.split("-")[0]
                tabela2 = {
                    "Tamanho do Terreno": tamanhoAnuncio,
                    "Local": localAnuncio,
                    "Horario do Anuncio": horarioAnuncio,
                    "Pagina do Anuncio": paginaAnuncio,
                }
                listaJson.append(tabela2)

                aquisicaoPaginaAnuncio(paginaAnuncio)
                aquisicaoAPIperfil(str(paginaAnuncio))

            except:
                print("Pulando as propagandas, aguarde...")

        print("Dados da pagina reunidos com sucesso.")


def aquisicaoPaginaAnuncio(paginaAnuncio):
    url = paginaAnuncio
    parametros = {
        "authority": "pr.olx.com.br",
        "method": "GET",
        "path": "/florianopolis-e-regiao/imoveis/terrenos",
        "scheme": "https",
        "referrer": "https://sc.olx.com.br/florianopolis-e-regiao/imoveis/terrenos",
        "sec-fetch-mode": "navigate",
        "sec-fetch-site": "same-origin",
        "sec-fetch-user": "?1",
        "upgrade-insecure-requests": "1",
        "user-agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/79.0.3945.130 Safari/537.36",
    }

    page = requests.get(url=url, headers=parametros)
    soup = BeautifulSoup(page.content, "lxml")
    anuncio = soup.find_all("div", {"class": "qp0wh1-3 cRfaNj"})

    for z in anuncio:
        try:
            tituloAnuncio = z.find_all("h1")[0].contents[0]
            precoAnuncio = z.find_all("h2")[0].contents[0]
            precoAnuncio = precoAnuncio.split("R$")[1]
            precoAnuncio = float(precoAnuncio.replace(".", ""))
            descricaoAnuncio = z.find_all(
                "span", class_="sc-1sj3nln-1 eOSweo sc-ifAKCX cmFKIN"
            )[0].contents[0]
            descricaoAnuncio = descricaoAnuncio.strip()

            tabela = {
                "Descricao do Anuncio": descricaoAnuncio,
                "Titulo do Anuncio": tituloAnuncio,
                "Preco do Terreno": precoAnuncio,
            }
            listaJson.append(tabela)
        except:
            print("Pulando as propaganda!")


def aquisicaoAPIperfil(paginaAnuncio):
    paginaAnuncio = paginaAnuncio.split("-")[-1]
    url = "https://prada-api.olx.com.br/store/v1/accounts/ads/" + str(paginaAnuncio)
    parametros = {
        "authority": "pr.olx.com.br",
        "method": "GET",
        "path": "/florianopolis-e-regiao/imoveis/terrenos",
        "scheme": "https",
        "referrer": "https://sc.olx.com.br/florianopolis-e-regiao/imoveis/terrenos",
        "sec-fetch-mode": "navigate",
        "sec-fetch-site": "same-origin",
        "sec-fetch-user": "?1",
        "upgrade-insecure-requests": "1",
        "user-agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/79.0.3945.130 Safari/537.36",
    }

    page = requests.get(url=url, headers=parametros)
    profile_json = json.loads(page.content)
    perfilNome = profile_json.get("nickname")
    tabela3 = {"Nome do Vendedor": perfilNome}
    listaJson.append(tabela3)


aquisicaodeDadosOLX(5)
df = pd.DataFrame(listaJson)
df.to_csv("desafio_seazona.csv")